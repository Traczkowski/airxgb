{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from math import sqrt\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "import pyproj as proj\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After making my imports, I worked with New York data as the base for my model\n",
    "\n",
    "### While it is certainly the case that other cities will function differently than New York, I wanted to build out my working model with this city, as it has the largest amount of data available to start and has a large variety of pricing options, I would really enjoy moving my price bins to reflect different cities better to increase the quality of my model in various cities. This is the version of my code without any amenities present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NY = pd.read_csv('data/NYListings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(strngy):\n",
    "    \"\"\"\n",
    "    Quick function to strip formatting from dollars\n",
    "    \"\"\"\n",
    "    dols = strngy.replace('$', '')\n",
    "    dols = dols.replace(',', '')\n",
    "    dols = float(dols)\n",
    "    return dols\n",
    "\n",
    "def clean_amens(amenity):\n",
    "    \"\"\"\n",
    "    Quick function to unpack amenities into list\n",
    "    \"\"\"\n",
    "    amenity = amenity.replace('{','')\n",
    "    amenity = amenity.replace('}','')\n",
    "    amenity = amenity.replace('\"','')\n",
    "    amenlist = amenity.split(',')\n",
    "    return amenlist\n",
    "    \n",
    "def clean_DF(DF, region):\n",
    "    \"\"\"\n",
    "    Clean_DF does what it says, it takes in a cityDF, then initially drops any columns\n",
    "    that won't be used, and proceeds to fill out ones that will be needed with some \n",
    "    assumed values.\n",
    "    \"\"\"\n",
    "    #Dropping undesirable columns...\n",
    "    DF = DF[desired]\n",
    "    \n",
    "    DF.cleaning_fee.fillna(value = '$0.00', inplace = True)\n",
    "\n",
    "    DF.price = DF.price.apply(clean_price)\n",
    "    DF.cleaning_fee = DF.cleaning_fee.apply(clean_price)\n",
    "\n",
    "    DF = DF[DF['price'] != 0]\n",
    "    DF = DF[np.isfinite(DF.bathrooms)]\n",
    "    DF = DF[np.isfinite(DF.bedrooms)]\n",
    "    DF = DF[np.isfinite(DF.beds)]\n",
    "    \n",
    "    #Drop Other property types, these accounted for a very small amount of rows\n",
    "    #it included various interesting structures such as yurts and teepees.\n",
    "    prop_types = ['Apartment', 'House', 'Townhouse', 'Loft', 'Condominium']\n",
    "    DF = DF[DF['property_type'].isin(prop_types)]\n",
    "    \n",
    "    \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired = [\n",
    " 'property_type','room_type','accommodates','bathrooms',\n",
    " 'bedrooms','beds','price','cleaning_fee', 'latitude', 'longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc = clean_DF(NY, 'New York City')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here I am just running my NY dataframe through the cleaning function, I ended up dropping many columns from the dataframe as I found them to have little signal after doing EDA on them. There were many columns that I thought would have significantly more signal. Ones with booleans, ones regarding host information, listing information, etc. Some of the columns I want to explore in the future would be the ones with regular language to see if there would be any NLP that can be done to try to get closer to the prices that are being asked for rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44853</th>\n",
       "      <td>House</td>\n",
       "      <td>Shared room</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.696762</td>\n",
       "      <td>-73.939594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      property_type    room_type  accommodates  bathrooms  bedrooms  beds  \\\n",
       "44853         House  Shared room             2       17.0       1.0   2.0   \n",
       "\n",
       "       price  cleaning_fee   latitude  longitude  \n",
       "44853   35.0          30.0  40.696762 -73.939594  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc[nyc.bathrooms == 17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above is a pretty classic example of a listing that would throw off any attempts at a model, this is why I will be cleaning the bedroom and bathroom columns below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.price = np.array(nyc.price)+np.array(nyc.cleaning_fee)\n",
    "nyc.drop(labels='cleaning_fee', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nyc.price.hist(bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47421"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc = nyc[nyc['price'] <= 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nyc.price.hist(bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45765"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.price = pd.cut(nyc.price, bins=[1,150,300,400,500], right=True) #best\n",
    "#nyc.price = pd.cut(nyc.price, bins=[1,100,200,300,400,500], right=True)\n",
    "#nyc.price = pd.cut(nyc.price, bins=[1,100,150,250,500], right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150]      26001\n",
       "(150, 300]    15189\n",
       "(300, 400]     3289\n",
       "(400, 500]     1286\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc.price.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc = nyc[nyc['bedrooms'] <= 5]\n",
    "nyc = nyc[nyc['beds'] <= 6]\n",
    "nyc = nyc[nyc['bathrooms'] <= 4]\n",
    "nyc = nyc[nyc['accommodates'] <= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45586"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here I am just showing how the histograms looked before and after the data cleaning, and showing how many entries I am losing as I clean up my data, going from ~47,500 non-zero priced listings to about ~45,500 as my input for my final model. One of the funny things to note here is the spike that happens near the round numbers of 200, 300, 400, and 500. In other cities this effect was much more pronounced, and can be seen in the presentation I have included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lon = np.array(nyc.longitude)\n",
    "input_lat = np.array(nyc.latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the next cell, I am converting the latitude and longitudes of NYC into meters using the Pyproj library, this is something that ended up causing me some grief with other cities that I was trying to predict on (so they will have a slightly different process, shown in a different file). The issue that I was coming across consistently was that cities east of the Mississippi river were coming up without any issues, while cities to the west would cause arrays full of \"inf\"s to appear. The issue was that the values entered here were tied to a UK grid, so they didn't extend all the way across the United States, just far enough for a few of the cites to work, while causing problems for others. The other model I make will use the latitude and longitude as straight X-Y coordinates instead of projecting them. At this point, I haven't found a working projection within Pyproj that I can use, but when I do I would be updating this code with my other cities, as converting everything to meters helped my predictions quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs_wgs = proj.Proj(init='epsg:4326') \n",
    "crs_bng = proj.Proj(init='epsg:27700') \n",
    "x_points, y_points = proj.transform(crs_wgs, crs_bng, input_lon, input_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_try = x_points/np.mean(x_points)\n",
    "y_try = y_points/np.mean(y_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_points = np.round(x_try, 4)\n",
    "new_y_points = np.round(y_try, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc['lats'] = new_x_points\n",
    "nyc['longs'] = new_y_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.price = [i.replace(')',']') for i in list(map(str, nyc.price))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms',\n",
       "       'beds', 'price', 'latitude', 'longitude', 'lats', 'longs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dum_nyc = nyc[['accommodates', 'bathrooms', 'bedrooms',\n",
    "       'beds', 'price', 'lats', 'longs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nodum = no_dum_nyc.drop('price', axis=1)\n",
    "y_nodum = no_dum_nyc.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nodum_train, x_nodum_test, y_nodum_train, y_nodum_test = train_test_split(x_nodum.values.tolist(), list(y_nodum), test_size=.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, criterion ='entropy', min_samples_split=2,\n",
    "                            min_samples_leaf=50, n_jobs=16, bootstrap=True, warm_start=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While creating my classifier, I was having issues with n_jobs = -1 (it wasn't showing 16 busy cores in htop for some reason, so I had manually set it to n_jobs = 16 and it began showing them all being busy in htop. I wasn't sure what had caused this, but the fix worked so I didn't change everything around for it. If you would like to run this code on a standard machine, I recommend setting -1 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rf(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    results = [1 if i == j else 0 for (i,j) in zip(predictions, test_labels)]\n",
    "    accuracy = sum(results)/len(results)\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.71%.\n",
      "0.7066204536480498\n",
      "Accuracy = 0.71%.\n",
      "0.7066643267669899\n",
      "Accuracy = 0.71%.\n",
      "0.7070153117185101\n",
      "Accuracy = 0.71%.\n",
      "0.7067081998859299\n",
      "Accuracy = 0.71%.\n",
      "0.7066204536480498\n",
      "Accuracy = 0.71%.\n",
      "0.7067959461238099\n",
      "Accuracy = 0.71%.\n",
      "0.7067959461238099\n",
      "Accuracy = 0.71%.\n",
      "0.7067959461238099\n",
      "Accuracy = 0.71%.\n",
      "0.70683981924275\n",
      "Accuracy = 0.71%.\n",
      "0.7067081998859299\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    rf.fit(x_nodum_train, y_nodum_train)\n",
    "    rf.n_estimators += 100\n",
    "    print (evaluate_rf(rf, x_nodum_test, y_nodum_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a nice piece of code I found online which allows me to very neatly output the feature importance in a dataframe, it is used below with XGBoost as well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                  index = x_nodum.columns,\n",
    "                                  columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>0.332861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longs</th>\n",
       "      <td>0.255548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.166973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lats</th>\n",
       "      <td>0.123917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>0.095467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>0.025235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              importance\n",
       "accommodates    0.332861\n",
       "longs           0.255548\n",
       "bedrooms        0.166973\n",
       "lats            0.123917\n",
       "beds            0.095467\n",
       "bathrooms       0.025235"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above code can be pretty easily ported to the other cities eastern cities (Boston, Washington DC, and New Orleans), however the western cities will cause problems, so they are in a more general model where I continue to use the latitude and longitude rather than meters. Below, I have included code for some searching of hyperparameters, and then I begin XGBoosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# # Number of trees in random forest\n",
    "\n",
    "# n_estimators = [100]\n",
    "\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(1, 7, num = 1)]\n",
    "\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2,4,5,6,7]\n",
    "\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [5,10,50,75,100,1000,5000]\n",
    "\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=140, cv=3, verbose=2, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the random search model\n",
    "# rf_random.fit(x_nodum_train, y_nodum_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, test_features, test_labels):\n",
    "#     predictions = model.predict(test_features)\n",
    "#     results = [1 if i == j else 0 for (i,j) in zip(predictions, test_labels)]\n",
    "#     accuracy = sum(results)/len(results)\n",
    "#     print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_random = rf_random.best_estimator_\n",
    "# random_accuracy = evaluate(best_random, x_nodum_test, y_nodum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### START XGBoost #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=16, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = XGBClassifier(objective='multi:softmax', n_jobs=16) #default estimators is 100\n",
    "xg.fit(np.array(x_nodum_train), np.array(y_nodum_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.86%\n"
     ]
    }
   ],
   "source": [
    "y_pred = xg.predict(x_nodum_test)\n",
    "accuracy = accuracy_score(y_nodum_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=16, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = XGBClassifier(objective='multi:softmax', n_estimators=1000, n_jobs=16) \n",
    "xg.fit(np.array(x_nodum_train), np.array(y_nodum_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.02%\n"
     ]
    }
   ],
   "source": [
    "y_pred = xg.predict(x_nodum_test)\n",
    "accuracy = accuracy_score(y_nodum_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.15, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=16, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = XGBClassifier(objective='multi:softmax', n_estimators=1000, learning_rate=0.15, n_jobs=16) \n",
    "xg.fit(np.array(x_nodum_train), np.array(y_nodum_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.93%\n"
     ]
    }
   ],
   "source": [
    "y_pred = xg.predict(x_nodum_test)\n",
    "accuracy = accuracy_score(y_nodum_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.63%\n"
     ]
    }
   ],
   "source": [
    "xg = XGBClassifier(objective='multi:softmax', n_estimators=3000, \n",
    "                   learning_rate=0.1, n_jobs=16) \n",
    "xg.fit(np.array(x_nodum_train), np.array(y_nodum_train))\n",
    "\n",
    "y_pred = xg.predict(x_nodum_test)\n",
    "accuracy = accuracy_score(y_nodum_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.07%\n"
     ]
    }
   ],
   "source": [
    "xg = XGBClassifier(objective='multi:softmax', n_estimators=1100, \n",
    "                   learning_rate=0.05, updater='grow_colmaker,prune', n_jobs=16) \n",
    "\n",
    "xg.fit(np.array(x_nodum_train), np.array(y_nodum_train))\n",
    "\n",
    "y_pred = xg.predict(x_nodum_test)\n",
    "accuracy = accuracy_score(y_nodum_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above, I spent some time trying to find the most accurate hyperparameters for XGBoost, there were many more iterations of this happening as well, but not all of them made it into the final code, as there would be times when I would simply throw code away when I made more significant improvements after the fact. Below, I show the feature importances for the final XGBoost classifier that I used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11149673, 0.06396814, 0.0716034 , 0.05487159, 0.33485553,\n",
       "       0.36320463], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(xg.feature_importances_,\n",
    "                                  index = x_nodum.columns,\n",
    "                                  columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>longs</th>\n",
       "      <td>0.363205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lats</th>\n",
       "      <td>0.334856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>0.111497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.071603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>0.063968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>0.054872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              importance\n",
       "longs           0.363205\n",
       "lats            0.334856\n",
       "accommodates    0.111497\n",
       "bedrooms        0.071603\n",
       "bathrooms       0.063968\n",
       "beds            0.054872"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
